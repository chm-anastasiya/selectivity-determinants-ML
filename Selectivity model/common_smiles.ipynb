{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a671b-8a26-4f50-a330-144faa67e9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cleaned_5HT5A.csv → trimmed.\n",
      "  cleaned_5HT7.csv → trimmed.\n",
      "  cleaned_5HT6.csv → trimmed.\n",
      "  cleaned_5HT2A.csv → trimmed.\n",
      "  cleaned_5HT2B.csv → trimmed.\n",
      "  cleaned_5HT1A.csv → trimmed.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# columns.py\n",
    "# ============================================================\n",
    "import glob, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "CSV_DIR = \"../Cleaned_data\"  # pathname\n",
    "OUT_DIR = Path(CSV_DIR) / \"trimmed\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "KEEP_COLS = [\"Molecule ChEMBL ID\", \"Smiles\",\n",
    "             \"Standard Type\", \"Standard Relation\", \"Standard Units\",\n",
    "             \"Receptor\", \"Standard Value\"]\n",
    "\n",
    "for fp in glob.glob(f\"{CSV_DIR}/cleaned_5HT*.csv\"):\n",
    "    df = pd.read_csv(fp)\n",
    "    if not set(KEEP_COLS).issubset(df.columns):\n",
    "        print(f\"Skip {fp.name}: missing columns\")\n",
    "        continue\n",
    "    (df[KEEP_COLS]\n",
    "        .dropna(subset=[\"Smiles\", \"Standard Value\"])\n",
    "        .to_csv(OUT_DIR / Path(fp).name, index=False))\n",
    "    print(f\"  {Path(fp).name} → trimmed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96acc67c-b5b6-4787-aa64-b091397c0b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  saved 15,975 rows to /Users/anastazja/magisterka 2024:2025/sem 1/phyton/Project/5HT5A/ML_LAB/5HT/ki_long.parquet\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# concat_long.py\n",
    "# Combine all trimmed cleaned_5HT*.csv into a single Parquet file\n",
    "# ============================================================\n",
    "\n",
    "import glob, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "SCRIPT_DIR = Path(\"..\")/\"Cleaned_data\"     \n",
    "TRIM_DIR   = SCRIPT_DIR / \"trimmed\"               \n",
    "TRIM_DIR.mkdir(exist_ok=True)                    \n",
    "\n",
    "out_long = SCRIPT_DIR / \"ki_long.parquet\"         \n",
    "\n",
    "\n",
    "dfs = [pd.read_csv(fp) for fp in glob.glob(f\"{TRIM_DIR}/cleaned_5HT*.csv\")]\n",
    "long_df = (pd.concat(dfs, ignore_index=True)\n",
    "             .drop_duplicates(subset=[\"Smiles\", \"Receptor\"]))\n",
    "\n",
    "long_df.to_parquet(out_long, index=False)\n",
    "print(f\"  saved {len(long_df):,} rows to {out_long}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027965b2-d115-40c6-ae81-5fd621302a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receptors in dataset: ['5HT5A' '5HT7' '5HT6' '5HT2A' '5HT2B' '5HT1A']\n",
      "SMILES in all receptors: 49\n",
      "Saved common SMILES list to  /Users/anastazja/magisterka 2024:2025/sem 1/phyton/Project/5HT5A/ML_LAB/5HT/ligands_for_inference.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# common_smiles.py \n",
    "# Extract SMILES present across all receptor datasets from a concatenated Parquet file\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "SCRIPT_DIR = Path(\"..\")/\"Cleaned_data\"        # script\n",
    "LONG_PATH  = SCRIPT_DIR / \"ki_long.parquet\" \n",
    "\n",
    "df = pd.read_parquet(LONG_PATH)\n",
    "\n",
    "receptors = df[\"Receptor\"].unique()\n",
    "print(\"Receptors in dataset:\", receptors)\n",
    "\n",
    "# Count how many receptors each SMILES appears in\n",
    "counts = (df.groupby(\"Smiles\")[\"Receptor\"]\n",
    "            .nunique()\n",
    "            .reset_index(name=\"n_receptors\"))\n",
    "\n",
    "common = counts[counts[\"n_receptors\"] == len(receptors)][\"Smiles\"]\n",
    "print(f\"SMILES in all receptors: {len(common)}\")\n",
    "\n",
    "out = Path(LONG_PATH).parent / \"ligands_for_inference.csv\"\n",
    "common.to_csv(out, index=False)\n",
    "print(f\"Saved common SMILES list to  {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712adc9-c50c-49ac-9cde-8125c1d65577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
